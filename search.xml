<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Web安全二：小心骗子(XSS、CSRF)]]></title>
    <url>%2F2017%2F08%2F02%2FWeb%E5%AE%89%E5%85%A8%E4%BA%8C%EF%BC%9A%E5%B0%8F%E5%BF%83%E9%AA%97%E5%AD%90%2F</url>
    <content type="text"><![CDATA[整个过程串起来看似天衣无缝，但是很多安全问题就是因为这个【cookie自动存储、自动携带】而产生引用自上篇文章，这篇文章就是来做说明的。XSS、CSRF这些词初听起来感觉挺牛逼的，在跟黑客这些词做下关联，瞬间觉得逼格很高，但当你知道他的原理以后，你就会觉得其实也没有多难。这里我要说的两个骗子就是xss和csrf。 前言浏览器通过cookie和session做关联，服务端就知道当前的请求属于谁了，具体可以参考我上一篇文章的“我是谁”部分。换句话说，只要你能搞到用户的cookie，你就可以伪造用户的请求。搞到用户cookie的方法很多，我们完全可以利用浏览器【cookie自动存储、自动携带】的原理来实现，XSS和CSRF就是两种实现方式。 XSS1、新浪微博XSS攻击：我们不说抽象的定义，来举个具体的例子，看下当年新浪微博是怎样被XSS攻击的，如下图。微博发帖的时候，我们不仅可以输入文字、图片，也可以输入javascript脚本，如果后台不对这些脚本做特殊处理，那么这些脚本就可以干坏事了。用户只是想看看微博，莫名奇妙的就关注了别人，可以看到5是在用户完全不知情的情况下，由浏览器自动完成的。脚本的作用是往服务器端发送关注请求，然后浏览器自动携带cookie到服务端，服务端区分用户靠的是cookie里的sessionid，sessionid还真是普通用户的sessionid，再然后就真的就关注成功了。 2、盗取cookie：步骤5我们再改一改，把请求不发给微博服务器，而是发给攻击者服务器，相比之前的攻击方式，这种方式攻击者可以拿到cookie的值，这样他就可以通过自己的浏览器来冒充其他用户，更加直接的去搞破坏。这里有个细节需要注意下，两台服务器的域名并不一样，cookie和域名是绑定的，所以往B站发请求，不会自动携带A站的cookie，但是可以通过javascript拿到A站的cookie，然后作为参数发给B。 关注是小事，改个密码、转个账可就不是小事了，xss还有很有破坏力的。 XSS防御1、转义：要解决此问题，关键是要屏蔽5的执行。通过服务端或者客户端，把用户输入的javascript脚本转化成普通文本，这样浏览器就不会执行这些脚本，也就没有后面的事情了。 2、CSP：但转义不是万能的，下面这种情况就不好转了，脚本可以不执行，但图片得显示啊。所以又有了个新的技术来解决此问题，我们叫做CSP，具体的介绍可以参考阮一峰老师的文章。CSP可以简单理解成是一种安全声明，图片中的脚本可以通过禁止内联函数执行来解决，实际项目中，CSP的配置可以直接参考我下面给出的配置。1&lt;img src="x" onerror="evil()"/&gt; 1234567891011 &lt;!-- Customize this policy to fit your own app's needs. For more guidance, see: https://github.com/apache/cordova-plugin-whitelist/blob/master/README.md#content-security-policy Some notes: * gap: is required only on iOS (when using UIWebView) and is needed for JS-&gt;native communication * https://ssl.gstatic.com is required only on Android and is needed for TalkBack to function properly * Disables use of inline scripts in order to mitigate risk of XSS vulnerabilities. To change this: * Enable inline JS: add 'unsafe-inline' to default-src --&gt;&lt;meta http-equiv="Content-Security-Policy" content="default-src 'self' data: gap: https://ssl.gstatic.com 'unsafe-eval'; style-src 'self' 'unsafe-inline'; media-src *; img-src 'self' data: content:;"&gt; 3、http-only：之前我们说过javascript可以拿到A站的cookie，然后作为参数发给B。针对于这块浏览器也有了安全防护措施，那就是扩展了cookie的类型。有http-only申明的cookie值，javascript无法获取，只有浏览器才可以获取，javascript获取不到自然就没东西可以发送了。下图是使用http-only的例子，cookie里的JSESSIONID就是http-only的。 xss攻击是由用户创造的内容产生的，所以项目中，我们需要重点关注用户创造的内容，如文章、个人资料等，加强对xss攻击的防范意识。 CSRF引用一张很经典的图来说明什么是CSRF。和XSS攻击一样，CSRF也是利用【cookie自动存储、自动携带】这一点，可以说XSS是在内部攻破，CSRF是在外部攻破。 1234567//get请求攻击&lt;img src=http://wooyun.org/csrf?xx=11 /&gt;//post请求攻击&lt;form action=http://wooyun.org/csrf.php method=POST&gt;&lt;input type="text" name="xx" value="11" /&gt;&lt;/form&gt;&lt;script&gt; document.forms[0].submit(); &lt;/script&gt; CSRF防御1、验证 HTTP Referer 字段：在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。WebB发给WebA的请求里Referer指向WebB，服务端做个白名单，过滤掉来源非法的请求即可。这种做法并不是完美的，一些比较低端的浏览器，可以改Referer（网站可以提醒用户换浏览器）；有些组织和个人会关闭Referer（毕竟是少部分人，可以暂时忽略）。实际使用不要把所有的请求都去做验证，否则百度搜到你后就无法打开你了，把关键的动态请求做下限制就够了。 2、可以再安全点：既然CSRF是利用cookie，如果我们的鉴权信息不放在cookie里，问题不就解决了吗。说的没错，服务端验证用户身份成功后，除了返回sessionid，可以再多返回一个随机字符串，同时对字符串做下存储（可以放在session里），客户端收到字符串后，把字符串存储在localStorage中，以后每次请求时，我们带上这个字符串到http请求头里，服务端在校验sessionid的基础上，再校验次字符串即可。 总结对于服务器来说，xss、csrf都不是用户真实的请求，而是攻击者利用浏览器的实现机制，去模拟用户发送的请求，在服务端看来，这些请求就是欺骗，在做web开发时我们一定要小心这些骗子。很多网站都存在漏洞，由于他们还没有做大做肥，所以攻击者并不怎么关注他们。随着业务的发展，程序员不能仅仅考虑功能的实现，这些可能出现的风险，心中都需要有数。]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web安全一：上网的过程中发生了什么(DNS、Cookie、Session)]]></title>
    <url>%2F2017%2F08%2F02%2FWeb%E5%AE%89%E5%85%A8%E4%B8%80%EF%BC%9A%E4%B8%8A%E7%BD%91%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[现代人的生活离不开网络，上网查资料也是家常便饭。上网查资料的过程，看似简单，但是它的实现非常复杂，为了更加快速、安全的上网，技术的革新从未停止过。本系列并不准备对上网过程中的每个细节做介绍，而是侧重于web安全，深入浅出的介绍下web安全相关的知识，精彩内容，不要错过。 上网的过程中发生了什么虽然是要说web安全，但我不急着说，只有知道这个过程是怎么跑通了以后，我们才能更加深入的理解web安全，所以一上来我先说上网的过程中发生了什么。当你使用浏览器输入www.baidu.com后，都发生了哪些事情呢，如图。 下面我把图里出现的一些词做个解释，为了方便讲解，我把用户的电脑叫做A机器，把web服务器叫做S机器。 域名解析：对于人类来讲域名是有意义的，但是对于计算机通信来说，域名是没有意义的，A、S两台机器通信，最重要的是要知道到对方的地址，也就是我们常说的IP。而域名解析的作用就是在正式通讯之前，把没意义的域名转化成有意义的IP。DNS服务器：域名解析是要通过DNS服务器来完成的，DNS服务器上存储了全球域名和IP的映射关系。当我们通过一些平台对购买的域名和主机做绑定的时候，这个信息会在DNS服务器上做同步。路由节点：互联网是由一个个独立的网络组合起来的，A、S两台机器处于不同的网络，为了能到达对方，需要走过很中间节点，我们叫做路由节点。请求资源：A机器知道S机器的IP后，就可以进行通信了。A发出来的请求，S能看懂，能看懂是因为请求的格式机器们早就约定好了，这个约定就是程序员常说的http传输协议。S知道A想干什么后，就开始啪啪啪的进行处理，然后把处理后结果反馈给A。接收响应：A机器拿到反馈，把反馈结果又给了浏览器，这些反馈结果包含图片、文本、html、css、javascript等，浏览器会对不同的资源做不同的处理。 实际上网过程中发生的事情远比这复杂，因为这个系列重点是要说web安全，其他不相干的信息暂时先不提及。 你是谁我们以用户登录系统查询自己账户余额场景为例，来说明下服务器是怎么区分用户的。如上图，1和5是浏览器发给服务器的请求，由于是短链接，对于服务器来说1和5是两个独立的请求，如果不做特殊的处理，服务器并不清楚1和5来自于同一个用户。用户发送第一个登录请求时，服务器把用户信息做了存储，存储的位置叫做session，同时生成一个sessionid，用来和session做对应。服务器把这个sessionid通过cookie告诉浏览器，浏览器会自动存储cookie，同时在后续的请求中，会自动携带cookie。当服务端收到下一个请求时，就可以从cookie获取到sessionid，并通过sessionid获取到session值，session里的用户信息就可以标识请求属于哪个用户了，这样服务器就可以清楚你是谁了。 备注1：这里是基于cookie会话维持技术，以及用的比较广泛http1.1协议来说。暂时不提及token鉴权、http2.0协议 备注2：sessionid并不是只在用户登录时生成，只要某个请求操作了session，如果之前没有sessionid，都会生成新的sessionid 备注3：并不是所有的sessionid在cookie里都叫做sessionid，这个可以自定义，只不过我们很少自己处理，都用web容器默认提供的 整个过程串起来看似天衣无缝，但是很多安全问题就是因为这个【cookie自动存储、自动携带】而产生，后续我会重点说明 讨厌的验证码验证码是为了防止工具的暴力破解而出现的，如果没有验证码，工具可以轻松的在一分钟的时间里，对你的密码进行上万次的尝试。现在的验证码越来越复杂，别说机器了，人都快受不了了，但是验证码是必须的。验证码使用的不合理，也会导致安全问题，这里我就来举两个新人常犯的错误。1、客户端验证码，如下图。对于工具来说，只关心网络协议，只要知道登录请求格式，就可以进行模拟。用户看起来是做了验证码验证，但那时浏览器自己在玩，工具根本不关心。2、验证码明文传输、验证码不清理，如下图。大家注意下红框部分，如果不以流的形式传输，工具可以轻松拿到验证码，并塞给后面的登录请求。如果不清理验证码，工具可以用同一个验证码做无数次的账号尝试。 弄好了验证码，但别高兴太早，验证码的破解技术也很强大。如果安全性要求特别高，最好在业务层对用户每天登录尝试次数做下限制。]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx]]></title>
    <url>%2F2017%2F08%2F01%2Fnginx%2F</url>
    <content type="text"><![CDATA[nginx是一个非常强大同时又非常轻量的中间件。尤其时对于后端人员来说，可以拿来干很多事，比如实现反向代理、负载均衡、https、添加缓存、请求改写等。前端人员也可以拿来发布静态页面。本文对nginx常用功能做些介绍，重点介绍如何配置，方便大家在日后的开发中使用。 windows系统安装nginx直接下载nginx安装包，解压后运行nginx.exe即可。 nginx文件夹下有个html目录，可以把静态资源放在下面，然后通过浏览器访问对应页面http://localhost/xxx.html即可。对于前端人员来说，掌握这些基本就够了。 CentOS系统安装nginx安装命令1yum install nginx 常用命令123service nginx &#123;start|stop|status|restart|reload&#125; nginxnginx -s &#123;stop|reload&#125; 配置文件总览12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788user nginx;#nginx开启后会启动2个进程master process，worker process。#本参数指定了master process以外的进程的用户。master process是用root启动的。worker_processes auto;#指定Nginx运行时使用的CPU核数。#设成auto会自动判断CPU的核数。error_log /var/log/nginx/error.log;pid /run/nginx.pid;#全局错误日志及PID文件include /usr/share/nginx/modules/*.conf;events &#123; worker_connections 1024; #单个后台worker process进程的最大并发链接数 &#125;http &#123; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; # 定义日志格式，常用参数如下 #1.$remote_addr 与$http_x_forwarded_for 用以记录客户端的ip地址； #2.$remote_user ：用来记录客户端用户名称； #3.$time_local ：用来记录访问时间与时区； #4.$request ：用来记录请求的url与http协议； #5.$status ：用来记录请求状态； #6.$body_bytes_s ent ：记录发送给客户端文件主体内容大小； #7.$http_referer ：用来记录从那个页面链接访问过来的； #8.$http_user_agent ：记录客户端浏览器的相关信息；。 access_log /var/log/nginx/access.log main; #记录访问日志，使用main格式 sendfile on; #指定是否使用OS的sendfile函数来传输文件。 #普通应用应该设为on，下载等IO重负荷的应用应该设为off。默认值是off。 tcp_nopush on; #sendfile为on时这里也应该设为on，数据包会累积一下再一起传输，可以提高一些传输效率。 tcp_nodelay on; #小的数据包不等待直接传输。默认为on。 #看上去是和tcp_nopush相反的功能，但是两边都为on时nginx也可以平衡这两个功能的使用。 keepalive_timeout 65; #HTTP连接的持续时间。设的太长会使无用的线程变的太多。设成0关闭此功能。 #charset UTF-8; #设置应答的文字格式，最好业务端自己设置 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #记录请求的原始ip到X-Real-IP中，首层代理设置，用于获取用户IP，后面无需设置，否则会被覆盖 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #添加请求的原始ip到X-Forwarded-For中 gzip on; #开启gzip压缩 gzip_min_length 1k; gzip_buffers 4 16k; #gzip_http_version 1.0; gzip_comp_level 1; gzip_types application/javascript text/css application/json image/jpeg image/png; gzip_vary off; gzip_disable "MSIE [1-6]\."; #gzip相关配置 include /etc/nginx/mime.types; default_type application/octet-stream; #设定mime类型,类型由mime.type文件定义 server &#123; listen 80; server_name localhost 127.0.0.1; location / &#123; root /usr/share/nginx/html; &#125; #后面重点介绍location error_page 404 /404.html; error_page 500 502 503 504 /50x.html; # 定义错误提示页面 &#125;&#125; 反向代理反向代理具体是什么，这里不多说，可以自行百度。这里只讲下和反响代理非常相关的一个配置项location。 location支持的表达式类型 ~ 表示执行一个正则匹配，区分大小写； ~* 表示执行一个正则匹配，不区分大小写 ^~ 表示普通字符匹配，使用前缀匹配。如果匹配成功，则不再匹配其他location = 进行普通字符精确匹配，也就是完全匹配 常规字符串匹配类型，使用前缀匹配。匹配优先级最低。 location表达式类型的优先级location的优先级和配置文件顺序没有太大关系，和location表达式的类型有关。相同类型的表达式，字符串长的会优先匹配。以下是按优先级排列说明： 等号类型（=）的优先级最高。一旦匹配成功，则不再查找其他匹配项。 ^~类型表达式。一旦匹配成功，则不再查找其他匹配项。 正则表达式类型（~ ~*）的优先级次之。如果有多个location的正则能匹配的话，则使用正则表达式最长的那个。 常规字符串匹配类型，使用前缀匹配。 1234567891011121314151617181920212223242526location = / &#123; #仅仅匹配请求 / [ configuration A ]&#125;location / &#123; #匹配所有以 / 开头的请求。 #但是如果有更长的同类型的表达式，则选择更长的表达式。 #如果有正则表达式可以匹配，则优先匹配正则表达式。 [ configuration B ]&#125;location /documents/ &#123; #匹配所有以 /documents/ 开头的请求。 #但是如果有更长的同类型的表达式，则选择更长的表达式。 #如果有正则表达式可以匹配，则优先匹配正则表达式。 [ configuration C ]&#125;location ^~ /images/ &#123; #匹配所有以 /images/ 开头的表达式，如果匹配成功，则停止匹配查找。 #所以，即便有符合的正则表达式location，也不会被使用 [ configuration D ]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; #匹配所有以 gif jpg jpeg结尾的请求。 #但是 以 /images/开头的请求，将使用 Configuration D [ configuration E ]&#125; root和aliasroot和alias可以用来发布静态资源，如图片、音频、页面等，但两者又有些细微的区别，具体如下。1234567891011location /request_path/image/ &#123; root /local_path/image/;&#125;#当客户端请求 /request_path/image/cat.png 的时候#nginx把请求映射为/local_path/image/request_path/image/cat.pnglocation /request_path/image/ &#123; alias /local_path/image/;&#125;#当客户端请求 /request_path/image/cat.png 的时候#nginx把请求映射为/local_path/image/cat.png proxy_passproxy_pass可以用来转发动态请求，配置起来也非常简单123location / &#123; proxy_pass http://one; &#125; 负载均衡负载均衡是高可用的解决方案，nginx也提供了对负载均衡的支持，同时提供了多种方案，具体如下。123456789101112131415161718192021222324252627282930313233http &#123; upstream one&#123; server 192.168.1.1:8080 weight=3; server 192.168.1.2; &#125; #轮询负载，可设置权重值。 #上面的例子在服务器后添加weight=3的配置，这意味着，每接收到4个请求，前3个请求会被分发到第一个服务器，第四个请求会分发到第二个服务器。 #后端机器性能不一致时会用 upstream two&#123; #least_conn server 192.168.1.1:8080; server 192.168.1.2; &#125; #请求会被转发到连接数最少的服务器上 #后端机器性能接近时会用 upstream three&#123; #ip_hash server 192.168.1.1:8080; server 192.168.1.2; &#125; #同一客户端连续的Web请求可能会被分发到不同的后端服务器进行处理 #希望用户的请求都到某台机器上处理时会用，如查看用户文本日志上下文 server &#123; listen 80; location / &#123; proxy_pass http://one; &#125; &#125;&#125; 添加缓存缓存的好处是减少服务端压力，尤其是动态请求，如果缓存用的好，能极大的减轻服务器的压力。nginx缓存使用了proxy_cache模块，启用缓存功能时，nginx还会额外启动两个进程：cache manager和cache loader。 12345678910111213141516171819202122232425262728293031http &#123; proxy_cache_path /usr/share/nginx/proxy_cache levels=1:2 keys_zone=one:200m inactive=1d max_size=10g; #设置Web缓存区名称为cache1 #内存缓存空间大小为200MB #1天没有被访问的内容自动清除 #硬盘缓存空间大小为10GB。 #levels=1:2 表示缓存目录的第一级目录是1个字符，第二级目录是2个字符,即/usr/share/nginx/proxy_cache/cache1/a/1b这种形式 server &#123; listen 80; location / &#123; proxy_pass http://127.0.0.1:8080; # nginx不会对root以及alias做缓存 proxy_cache one; #设置资源缓存的zone proxy_cache_key $host$uri$is_args$args; #设置缓存的key，以域名、URI、参数组合成Web缓存的Key值，Nginx根据Key值哈希，存储缓存内容到二级缓存目录内 proxy_cache_valid 200 304 12h; #对不同的HTTP状态码设置不同的缓存时间 expires 1d; #缓存时间 proxy_ignore_headers X-Accel-Expires Expires Cache-Control Set-Cookie; #忽略原始服务器上的响应设置 proxy_hide_header Cache-Control; #隐藏Cache-Control proxy_hide_header Set-Cookie; #隐藏Set-Cookie add_header Cache-Status "$upstream_cache_status"; #添加响应码 &#125; &#125;&#125; httpshttps主要是出于传输安全考虑，具体怎么做到安全可以参考我的这篇文章12345678910111213141516server &#123; listen 443 ssl http2 default_server; listen [::]:443 ssl http2 default_server; server_name _; root /usr/share/nginx/html; ssl_certificate "/etc/pki/nginx/server.crt";#证书路径 ssl_certificate_key "/etc/pki/nginx/private/server.key";#key路径 ssl_session_cache shared:SSL:1m; #储存SSL会话的缓存类型和大小 ssl_session_timeout 10m;#会话过期时间 ssl_ciphers HIGH:!aNULL:!MD5;#为建立安全连接，服务器所允许的密码格式列表 ssl_prefer_server_ciphers on;#依赖SSLv3和TLSv1协议的服务器密码将优先于客户端密码 location / &#123; &#125;&#125; 请求改写nginx收到请求后，转发给其他的url，有时不仅仅的替换host、port那么简单，需要改写url中的一些值，比如将虚拟目录做修改等，这里介绍了几种nginx常用的改写方法。 rewrite break - url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 rewrite last - url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变 rewrite redirect – 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时） rewrite permanent – 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
        <tag>后台</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字签名是什么]]></title>
    <url>%2F2017%2F08%2F01%2F%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[CA、数字证书这些概念一直理解的模模糊糊，直到看到阮一峰大神的一篇文章，一下子清楚了很多。文章举了一个很生动的例子来解释什么是数字证书、CA，具体如下。 转载自阮一峰大神的博客：数字签名是什么 1） 鲍勃有两把钥匙，一把是公钥，另一把是私钥。 2）鲍勃把公钥送给他的朋友们—-帕蒂、道格、苏珊—-每人一把。 3）苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。 4）鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。 5）鲍勃给苏珊回信，决定采用”数字签名”。他写完后先用Hash函数，生成信件的摘要（digest）。 6）然后，鲍勃使用私钥，对这个摘要加密，生成”数字签名”（signature）。 7）鲍勃将这个签名，附在信件下面，一起发给苏珊。 8）苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。 9）苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。 10）复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成”数字签名”，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。 11）后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找”证书中心”（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成”数字证书”（Digital Certificate）。 12）鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。 13）苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明”数字签名”是否真的是鲍勃签的。 14）下面，我们看一个应用”数字证书”的实例：https协议。这个协议主要用于网页加密。 15）首先，客户端向服务器发出加密请求。 16）服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。 17）客户端（浏览器）的”证书管理器”，有”受信任的根证书颁发机构”列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。 18）如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。 19）如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。 20）如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。 最后再附上一张整体的图来说明]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>数字签名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo静态博客]]></title>
    <url>%2F2017%2F08%2F01%2Fother_hexo%2F</url>
    <content type="text"><![CDATA[最近有时间折腾下个人博客，在对比了几家之后，最终决定用Hexo作为框架。选择Hexo的原因很多，首先是静态博客，服务器开销小。其次是简洁，支持markdown语法，用起来舒服。再次是可以直接发布到github pages上。最后是插件很多，可以DIY。在博客搭建的过程中也踩了些坑，在这里做下记录，也方便大家搭建个人博客时做参考。 hexo安装依赖nodejs环境，按照hexo官网的命令操作即可，我也把命令贴在了下面。有个小的细节需要注意，官网提供了多语言支持，可以切换成简体中文，对于我这种更喜欢看中文文档的人，这个功能还是很不错的。12345npm install hexo-cli -ghexo init blogcd blognpm installhexo server hexo-admin可视化后台安装安装完hexo后，就可以写文章了，但得通过命令行的方式创建文章，还得找个markdown的编辑器，这点不是很易用，我们更希望有一个可视化的编辑后台，这个时候hexo-admin就派上用场了。通过npm进行安装，安装命令如下。安装完成后，打开http://localhost:4000/admin/ ，即可进行可视化编辑。hexo-admin支持markdown编辑，支持贴图，支持添加分类、标签。虽然整个后台看起来比较简单，但是很实用。1npm install --save hexo-admin NexT皮肤安装hexo支持皮肤，我选择了经典的NexT 皮肤，NexT 皮肤的官方文档写的非常详细，github上的关注度也非常高。实际使用时，感觉这套皮肤每个细节考虑的都很周到，遇到问题基本都可以通过官方文档来找到解决办法。皮肤安装依赖git，按照官网提供的命令执行即可12cd your-hexo-sitegit clone https://github.com/iissnan/hexo-theme-next themes/next 如何设置「阅读全文」在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。 NexT 提供三种方式来控制文章在首页的显示，具体可以参考http://theme-next.iissnan.com/faqs.html#read-more。我的博客是一、二两种结合着使用。同时这个设置对seo也有影响，设置的内容会成为页面的描述信息。 添加分类、标签页按照分类、标签查看文章是个比较基本的需求。NexT皮肤默认并没有这两个页面，需要按照文档说明自己添加下。添加标签页说明：http://theme-next.iissnan.com/theme-settings.html#tags-page添加分类页说明：http://theme-next.iissnan.com/theme-settings.html#categories-page 站内搜索文章较多时，需要有文章搜索功能，我选择了local-search插件。添加站内搜索说明：http://theme-next.iissnan.com/third-party-services.html#local-search 404页面、自定义页面如果你不仅仅满足于NexT所提供的页面，你也可以添加自己的页面。但记住，这些页面需要放在皮肤的source文件夹下，这样在发布和部署时就能很方便的一起打包。之前自己将页面放在了根目录的source下，页面发布出来就不是自己想要的样子了。 部署到github page当初选择hexo，一个重要的原因是可以部署到github page。官网提供了一键部署的工具，操作起来没什么坑，可以参考官方文档https://hexo.io/zh-cn/docs/deployment.html#Git。但是，实际使用时，发现github page访问速度太慢，体验不是很好。 部署到自己的服务器上github page速度太慢，于是选择部署在自己的ECS服务器上，用nginx发布静态文件，用CDN做加速，访问速度还不错。每次写完文章后，懒得手动上传文件，那么就通过插件来上传。开始试了FTPSync，通过FTP协议进行上传，我用vsftp配置好了FTP服务，但每次文件传一半就失败，不知道什么原因。后来换了SFTP插件https://hexo.io/docs/deployment.html#SFTP，通过ssh协议进行上传，很快就可以调通，所以也推荐这种方式进行一键部署。 评论评论功能一直没有搞定，试了很多，都不满意。网易云跟贴、多说因为要关闭，没法使用，放弃。友言太老，还停留再开心网的时代，放弃。disqus要翻墙才能用，放弃。HyperComments聊天框是繁体中文，放弃。畅言可以用，但支持的登录方式有点少，同时右下角弹框太多，找了半天也没法关闭，目前作为备选方案。也在持续的找评论插件，如果有满意的，也会尽快添加此功能，并更新此文章。 其他配置头像、社交账号，RSS订阅、百度统计、版权声明等，这些都可以在Next官方文档上找到对于说明，没有什么坑，只要仔细阅读文档，按照操作即可。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>NexT</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web性能优化实践]]></title>
    <url>%2F2017%2F07%2F31%2Fweb_performance_yahoo%2F</url>
    <content type="text"><![CDATA[用户体验这几年被提及的越来越多，产品不再仅仅满足于实现功能，对于用户的使用感受也越来越重视。加载延迟、操作卡顿这些性能问题，都会严重影响用户体验，尤其在手机端，这些问题会被放大。那么如何来做性能优化呢？雅虎的工程师，总结了一套web性能优化最佳实践，业内俗称雅虎军规，雅虎军规目前一共35条，写的非常详细。本文参考雅虎军规，侧重于实践，结合项目来看下如何做优化，以及优化所带来的提升。 雅虎军规原文：https://developer.yahoo.com/performance/rules.html雅虎军规译文：http://www.cnblogs.com/li0803/archive/2009/09/20/1570581.html 前阵子做了个手机App，用的是混合开发模式，技术选型是cordova+vue.js。我也就以此项目为例，看下如何做性能优化。 未经优化项目开发完成后，部署到自己的ECS（1M带宽）上，自测发现页面需要很长时间才能显示出来。于是我用https://gtmetrix.com/进行了测试，结果如下。这是使用电脑、有线、且只有一个人访问的情况下看到的数据。如果用手机、无线、且多人访问，那数据更是惨不忍睹，所以必须要进行优化。 CDN加速之前我提过，我用的ECS带宽是1M，有点小，那么为什么不加大带宽呢？原因如下： 要钱，一个月得多花个一两百块钱。对于我这样的独立开发者，是要精打细算过日子的。 带宽加到多少合适？这个不好评估。有人说可以按量付费，阿里云的流量是0.8元/GB，看起来还能接受。 有没有更好的解决办法呢，PageSpeed和YSlow给出的建议里，都有使用CDN加速。 CDN可以让资源分发到离用户最近的节点，用户经过较少的路由，就能快速获取资源，因此可以提供比服务器带宽更好的服务效果。 CDN的带宽是共享的，不需要担心下载速度。 CDN的费用相比服务器带宽要便宜，阿里云的CDN带宽是0.272元/GB。 效果好还便宜，所以我们选择CDN，下面是经过cdn加速后的结果。 压缩、gzip压缩的好处，首先是下载快，其次是省流量省钱。具体做法： 首先是对原始文件进行压缩。如文本文件去空格，vue构建工具已经做了此事；图片缩减大小，我通过此网站对图片都做了处理。 其次是服务端开启gzip压缩。 实际使用时，我将ECS作为CDN的回源服务器，先对ECS上的资源做了处理，通过nginx开启gzip压缩（配置代码如下）。然而阿里云的CDN并不是像我想的那样，将我给他的东西原封不动的给用户，阿里云默认并不开启gzip压缩，需要自己去设置下。 12345678gzip on;gzip_min_length 1k;gzip_buffers 4 16k;#gzip_http_version 1.0;gzip_comp_level 1;gzip_types application/javascript text/css application/json image/jpeg image/png;gzip_vary off;gzip_disable "MSIE [1-6]\."; 加速后的效果 过期时间参考facebook的过期时间设置，我也添加了相应的cache-control和expires头，设置成永不过期，如果需要更新，可以通过构建加md5后缀的方式来绕开缓存。截图里还有两个很重要的响应头，ETag和Last-Modified，大家可以自行百度看下他俩的作用。不过通过chrome进行测试发现，加不加这两个头对于资源是否重新请求影响不大。个人猜测应该是现代浏览器比较智能，可以基于资源类型判断是否需要缓存。所以对于这点是否要优化，我也持保留意见。后续也会对这块进行深入学习，更新这块的知识点。 其他性能优化过程中还有几个比较重要的点，因为vue框架已经帮我们做过，我们可能并未察觉，但我要在这里再提下。 css需要写在头部；js需要写在底部。这样可以减少白屏时间，让用户更早的看到页面。 css、js合并，这个可以通过构建工具来完成。 总结雅虎军规很经典，很详细，实际使用中，不少的点因为历史发展原因，我们不一定能遇到。实际项目中可以重点考虑CDN加速、资源压缩、资源合并这三个点，配合评分工具，对网站性能做提升。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web开发小工具]]></title>
    <url>%2F2017%2F07%2F30%2Fweb_tools%2F</url>
    <content type="text"><![CDATA[分辨率统计web开发时，一般会有分辨率适配的需求。这时我们首先要做的是，了解当下主流分辨率，以便做重点测试。相关数据可以参考【百度分辨率统计】。 分辨率效果查看页面合成时，我们希望能同时看到不同分辨率下的页面效果。推荐【响应式设计开发工具】 分辨率检测真机测试发现问题时，我们需要获取真机的分辨率信息。推荐【此工具】，可以查看分辨率，dpr等重要信息。 html5支持度评分检测当前浏览器对于html5的支持程度，给出相应分数、详细说明，【在线地址】。使用场景是，发现某个设备有兼容性问题时，运行下来定位原因。 Html5支持度统计在使用一些h5新特性时，有必要了解下此特性的兼容情况，【在线地址】。同时此工具可以以国家为单位，提供支持度统计数据。 性能评分工具非常优秀的一款网页性能评分工具，性能标准参考了google的PageSpeed，yahoo的Yslow。【在线地址】。性能优化是个大的话题，我会用单独的文章来写。大家可以先用下此工具，看下自己做的项目能得多少分，有哪些地方可以优化，尤其是我红色标出的4个tab，需要重点看下。 其他小工具 二维码生成/解码 【在线地址】 正则测试【在线地址】 加解密 【在线地址】 图片压缩 【在线地址】 屏幕取色工具 【下载地址】]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>工具</tag>
      </tags>
  </entry>
</search>